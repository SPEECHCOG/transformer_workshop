{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE with convolutional layer and attention\n",
    "\n",
    "![VAE + Conv1D encoder + Attention](img/vae_cnn1d_att_arch.png)\n",
    "\n",
    "## Attention in Keras\n",
    "\n",
    "Dot-product attention (Luong et al., 2015)\n",
    "\n",
    "```python\n",
    "    tf.keras.layers.Attention(use_scale=False, **kwargs)\n",
    "```\n",
    "\n",
    "$\\large score(s_t, h_i) = s_t^TW_ah_i$\n",
    "\n",
    "$\\large score(s_t, h_i) = s_t^Th_i$\n",
    "\n",
    "\n",
    "### Procedure\n",
    "\n",
    "1. Dot product of query and value, that is $s_t^Th_i$ ->  `scores = tf.matmul(query, key, transpose_b=True)`\n",
    "1. Softmax (weights), $\\large \\alpha_{t,i} = \\frac{exp(score_{ti})}{\\sum_{k=1}^{N}{exp(score_{tk})}}$ -> `distribution = tf.nn.softmax(scores)`\n",
    "1. Weighted values using the output of softmax, $\\alpha \\cdot h$ -> `tf.matmul(distribution, value)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and dependencies\n",
    "# VAE from https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Attention, Input, Dense, GRU, Reshape, Lambda, Conv1D, \\\n",
    "                                    GlobalAveragePooling1D, MaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from tensorflow.keras import backend as K # operations with tensors\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalisation\n",
    "x_train = x_train.astype('float32') / 255 # 255 max rgb value\n",
    "x_test = x_test.astype('float32') / 255\n",
    "x_train = x_train.reshape(len(x_train), np.prod(x_train.shape[1:]))\n",
    "x_test = x_test.reshape(len(x_test), np.prod(x_test.shape[1:]))\n",
    "\n",
    "input_dim = x_train.shape[1]\n",
    "\n",
    "# parameters\n",
    "intermediate_dim = 32 # dimension of points in the latent space\n",
    "batch_size = 128 \n",
    "latent_dim = 2 # the two latent parameters z_mean and z_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture\n",
    "\n",
    "inputs = Input(shape=(input_dim,), name='encoder_input')\n",
    "\n",
    "\n",
    "# encoder (x -> z_mean & x -> z_log_var) A 'Y' shape\n",
    "encoder_1 = Conv1D(filters=intermediate_dim, kernel_size=14, strides=7, padding='same')\n",
    "encoder_out_1 = encoder_1(Reshape((input_dim,1))(inputs)) # B x timesteps (pixels) x features ([0,1])\n",
    "maxpool = MaxPool1D(pool_size=2)\n",
    "encoder_out_1 = maxpool(encoder_out_1)\n",
    "encoder_2 = Conv1D(filters=intermediate_dim, kernel_size=2, padding='same')\n",
    "encoder_out_2 =encoder_2(encoder_out_1)\n",
    "encoder_out_2 = maxpool(encoder_out_2)\n",
    "\n",
    "# attention\n",
    "self_attention_out = Attention()([?, ?])\n",
    "\n",
    "self_attention_out = Reshape((K.prod(self_attention_out.shape[1:]),))(self_attention_out)\n",
    "encoder_out_2 = Reshape((K.prod(encoder_out_2.shape[1:]),))(encoder_out_2)\n",
    "\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "attention_out = Concatenate()([?, ?])\n",
    "\n",
    "encoder_3 = Dense(intermediate_dim, activation='relu')\n",
    "encoder_out_3 = encoder_3(attention_out)\n",
    "\n",
    "z_mean = Dense(latent_dim, name='z_mean')\n",
    "z_mean_out = z_mean(encoder_out_3)\n",
    "z_log_sigma = Dense(latent_dim, name='z_log_sigma')\n",
    "z_log_sigma_out = z_log_sigma(encoder_out_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling\n",
    "from tensorflow.keras import backend as K # operations with tensors\n",
    "\n",
    "def sampling(params):\n",
    "    z_mean, z_log_sigma = params\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim)) # mean = 0, std = 1\n",
    "    return z_mean + K.exp(0.5 * z_log_sigma) * epsilon #\n",
    "\n",
    "# We need to wrap the output of sampling into a layer for connecting it with the decoder. For that we can\n",
    "# a Lambda layer\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))\n",
    "z_out = z([z_mean_out, z_log_sigma_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "decoder_1 = Dense(intermediate_dim, activation='relu')\n",
    "decoder_2 = Dense(input_dim, activation='sigmoid')\n",
    "decoder_1_out = decoder_1(z_out)\n",
    "decoder_2_out = decoder_2(decoder_1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "\n",
    "# end-to-end autoencoder\n",
    "vae = Model(inputs, decoder_2_out) \n",
    "\n",
    "# from inputs to latent space\n",
    "encoder_model = Model(inputs, z_mean_out) \n",
    "\n",
    "# generator\n",
    "decoder_input = Input(shape=(latent_dim, ))\n",
    "#_decoder_1_out = decoder_1(decoder_input)\n",
    "#_decoder_2_out = decoder_2(_decoder_1_out)\n",
    "generator = Model(decoder_input, decoder_2(decoder_1(decoder_input)))\n",
    "print(vae.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "\n",
    "# Reconstruction loss and KL divergence\n",
    "def vae_loss(true, pred):\n",
    "    l_re = binary_crossentropy(true, pred) * input_dim\n",
    "    d_kl = - 0.5 * K.mean(1 + z_log_sigma_out - K.square(z_mean_out) - K.exp(z_log_sigma_out), axis=-1)\n",
    "\n",
    "    loss = l_re + d_kl\n",
    "    return loss\n",
    "\n",
    "vae.compile(optimizer=Adadelta(learning_rate=1.0), loss=vae_loss, experimental_run_tf_function=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train \n",
    "vae.fit(x_train, x_train,\n",
    "       shuffle=True,\n",
    "       epochs=20,\n",
    "       batch_size=batch_size,\n",
    "       validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded = encoder_model.predict(x_test, batch_size=batch_size)\n",
    "\n",
    "# distributions of the different classes\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"z[0]\")\n",
    "plt.ylabel(\"z[1]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display generator usin random values within the interval\n",
    "# shown by the encoder [-4,4]\n",
    "def generate_digits(n):\n",
    "    digit_size = 28\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "    # we will sample n points within [-4, 4] standard deviations\n",
    "    grid_x = np.linspace(-4, 4, n) # value obtain with the encoder\n",
    "    grid_y = np.linspace(-4, 4, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_x):\n",
    "        for j, xi in enumerate(grid_y):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = generator.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[i * digit_size: (i + 1) * digit_size,\n",
    "                   j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # axis labels \n",
    "    start_range = digit_size // 2\n",
    "    end_range = (n - 1) * digit_size + start_range + 1\n",
    "\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "\n",
    "    plt.imshow(figure)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_digits(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def see_images(dataset, n):\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(dataset[i].reshape(28,28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = vae.predict(x_test)\n",
    "\n",
    "# Visualisation of predictions\n",
    "see_images(x_test, 5)\n",
    "see_images(prediction, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
